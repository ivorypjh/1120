{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b27ca3",
   "metadata": {},
   "source": [
    "## 공용 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1ec2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬\n",
    "# ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해 %matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "    \n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "# Jupyter Notebook의 출력을 소수점 이하 3자리로 제한\n",
    "%precision 3\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# 시드 고정\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d246462b",
   "metadata": {},
   "source": [
    "## 장르 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d5040",
   "metadata": {},
   "source": [
    "### 세부 장르 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e4dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV 시사&교양-기타\n",
      "TV 시사&교양-인물&다큐\n",
      "TV 연예&오락-기타\n",
      "TV드라마-기타\n",
      "TV드라마-외화 시리즈\n",
      "TV애니메이션-기타\n",
      "TV애니메이션-명랑&코믹\n",
      "TV애니메이션-액션&모험\n",
      "TV애니메이션-추리&미스터리\n",
      "TV애니메이션-학원&순정&연애\n",
      "다큐-인물\n",
      "영화-SF&환타지\n",
      "영화-공포&스릴러\n",
      "영화-다큐멘터리\n",
      "영화-단편\n",
      "영화-드라마\n",
      "영화-로맨틱코미디\n",
      "영화-멜로\n",
      "영화-무협\n",
      "영화-애니메이션\n",
      "영화-액션&어드벤쳐\n",
      "영화-역사\n",
      "영화-코미디\n",
      "우리동네-연예&오락\n",
      "키즈-기타\n",
      "키즈-애니메이션\n",
      "키즈-오락\n",
      "키즈-학습\n",
      "\n",
      "['TV 시사&교양-기타', 'TV 시사&교양-인물&다큐', 'TV 연예&오락-기타', 'TV드라마-기타', 'TV드라마-외화 시리즈', 'TV애니메이션-기타', 'TV애니메이션-명랑&코믹', 'TV애니메이션-액션&모험', 'TV애니메이션-추리&미스터리', 'TV애니메이션-학원&순정&연애', '다큐-인물', '영화-SF&환타지', '영화-공포&스릴러', '영화-다큐멘터리', '영화-단편', '영화-드라마', '영화-로맨틱코미디', '영화-멜로', '영화-무협', '영화-애니메이션', '영화-액션&어드벤쳐', '영화-역사', '영화-코미디', '우리동네-연예&오락', '키즈-기타', '키즈-애니메이션', '키즈-오락']\n"
     ]
    }
   ],
   "source": [
    "# 파일에서 세부 장르 데이터 가져오기\n",
    "\n",
    "open_file = open('./text files/detail_genre.txt', 'r', encoding = 'utf8')\n",
    "text = open_file.read()\n",
    "open_file.close()\n",
    "\n",
    "# 파일에서 읽어온 데이터 확인\n",
    "print(text)\n",
    "\n",
    "data_list = text.split('\\n')\n",
    "\n",
    "# data_list 의 마지막에 공백이 추가되므로 공백 제거\n",
    "data_list = data_list[:-2]\n",
    "# 확인\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244f864",
   "metadata": {},
   "source": [
    "### 불용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff49afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text files/stopword.txt', 'r', encoding = 'utf-8') as f:\n",
    "    stopwords = f.read()\n",
    "\n",
    "#print(type(stopwords))\n",
    "stopwords_list = stopwords.split('\\n')\n",
    "#print(stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91476bf1",
   "metadata": {},
   "source": [
    "### 세부 장르별 단어 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1208ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3afccc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict_data = {}\n",
    "\n",
    "# 각 세부 장르 별로 단어 리스트 생성하고 저장\n",
    "for detail_genre in data_list:\n",
    "    # 각 세부 장르에 대해 단어 데이터 가져오기\n",
    "    open_file = open('./text files/' + detail_genre + '_words.txt', 'r', encoding = 'utf8')\n",
    "    text = open_file.read()\n",
    "    \n",
    "    # 파일 닫기\n",
    "    open_file.close()\n",
    "    \n",
    "    # 각 단어 분리하기\n",
    "    text_list = text.split('\\n')\n",
    "    text_list = text_list[:-2] # 마지막의 공백 제외\n",
    "    \n",
    "    # 각 세부 장르별 줄거리의 단어 갯수 확인 => 가장 단어의 갯수가 적은 경우는 15개\n",
    "    #no_dup = set(text)\n",
    "    #print(detail_genre, ' : ', len(text), len(no_dup))\n",
    "    \n",
    "    # 각 장르별 주요 단어 찾기\n",
    "    spliter = Twitter()\n",
    "    nouns_for_dictionary = spliter.nouns(text)\n",
    "    ko = nltk.Text(nouns_for_dictionary, name = detail_genre)\n",
    "    \n",
    "    \n",
    "    # 불용어 제거\n",
    "    ko1 = [each_word for each_word in ko if each_word not in stopwords_list]\n",
    "    ko = nltk.Text(ko1, name = detail_genre)\n",
    "    word_dict = dict(ko.vocab())\n",
    "\n",
    "    # 확인\n",
    "    #print(type(word_dict))\n",
    "    sorted_dictionary = sorted(word_dict.items(), key = lambda item: item[1], reverse = True)\n",
    "    #print(sorted_dictionary)\n",
    "    \n",
    "    # 단어 리스트를 dict 형태로 저장\n",
    "    word_dict_data[detail_genre] = word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7242ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "않다 이다\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_list[0], stopwords_list[6])\n",
    "print(type(stopwords_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cfa11c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'땅': 1,\n",
       " '기운': 1,\n",
       " '점': 1,\n",
       " '인간': 1,\n",
       " '운명': 1,\n",
       " '수': 1,\n",
       " '천재': 1,\n",
       " '지관': 1,\n",
       " '박재상': 1,\n",
       " '명당': 1,\n",
       " '이용': 1,\n",
       " '천하': 1,\n",
       " '권력': 1,\n",
       " '장동': 1,\n",
       " '김씨': 1,\n",
       " '가문': 1,\n",
       " '계획': 1,\n",
       " '가족': 1,\n",
       " '후': 1,\n",
       " '복수': 1,\n",
       " '왕족': 1,\n",
       " '흥선': 1}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict_data['영화-역사']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecfa2eb",
   "metadata": {},
   "source": [
    "### 세부 장르별 단어 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff6f1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e951fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 장르별 단어 저장하기\n",
    "\n",
    "# 장르별 벡터 저장\n",
    "word_vector_dict = {}\n",
    "\n",
    "okt = Okt()\n",
    "vectorizer = CountVectorizer(min_df = 0.05)\n",
    "    \n",
    "# dict 형태로 저장되어 있는 단어 데이터를 읽고\n",
    "# 각 단어들을 모아서 하나의 문장으로 만든 다음 저장\n",
    "for detail_genre in data_list:\n",
    "    contents_tokens = word_dict_data[detail_genre]\n",
    "\n",
    "    # 벡터화를 위해 단어들을 가지고 문장 생성\n",
    "    contents_for_vect = []\n",
    "    sentence = ''\n",
    "    # 토큰 단위로 구분된 문장을 생성\n",
    "    for content in contents_tokens:\n",
    "        sentence += ' ' + content\n",
    "\n",
    "    # 생성한 문장을 리스트에 추가\n",
    "    contents_for_vect.append(sentence)\n",
    "    \n",
    "    word_vector_dict[detail_genre] = contents_for_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "34b47685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vector_dict['TV 시사&교양-기타'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9b007311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 아이스크림 모기 탭댄스 버섯 껌 빙판 빨대 식충식물 달팽이 코골 팝콘 수족관 햄 초능력 파리 스파게티']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents_for_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92711b89",
   "metadata": {},
   "source": [
    "## 샘플 줄거리 데이터를 활용해서 거리 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7869e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d58c3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 데이터와 훈련 데이터 거리 확인\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "#거리 구해주는 함수 생성\n",
    "def dist_raw(v1, v2):\n",
    "    # 차이를 계산\n",
    "    delta = v1 - v2\n",
    "    \n",
    "    return sp.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "04eaa1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "eb22f1f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV 시사&교양-기타 장르와의 거리는 : \t8.587169321076978\n",
      "TV 시사&교양-기타 장르와의 거리(원본)는 : \t36.932370625238775\n",
      "TV 시사&교양-기타 장르와의 일치율은 : \t80.0%\n",
      "TV 시사&교양-기타 장르의 단어 길이는 : \t1371\n",
      "\n",
      "TV 연예&오락-기타 장르와의 거리는 : \t4.438721461438541\n",
      "TV 연예&오락-기타 장르와의 거리(원본)는 : \t62.5939294181153\n",
      "TV 연예&오락-기타 장르와의 일치율은 : \t70.0%\n",
      "TV 연예&오락-기타 장르의 단어 길이는 : \t3924\n",
      "\n",
      "TV드라마-기타 장르와의 거리는 : \t6.06106949245715\n",
      "TV드라마-기타 장르와의 거리(원본)는 : \t48.75448697299562\n",
      "TV드라마-기타 장르와의 일치율은 : \t60.0%\n",
      "TV드라마-기타 장르의 단어 길이는 : \t2382\n",
      "\n",
      "TV드라마-외화 시리즈 장르와의 거리는 : \t4.837502111176168\n",
      "TV드라마-외화 시리즈 장르와의 거리(원본)는 : \t58.42944463196617\n",
      "TV드라마-외화 시리즈 장르와의 일치율은 : \t50.0%\n",
      "TV드라마-외화 시리즈 장르의 단어 길이는 : \t3418\n",
      "\n",
      "영화-공포&스릴러 장르와의 거리는 : \t19.508777898098554\n",
      "영화-공포&스릴러 장르와의 거리(원본)는 : \t19.595917942265423\n",
      "영화-공포&스릴러 장르와의 일치율은 : \t50.0%\n",
      "영화-공포&스릴러 장르의 단어 길이는 : \t388\n",
      "\n",
      "영화-드라마 장르와의 거리는 : \t11.878666268561824\n",
      "영화-드라마 장르와의 거리(원본)는 : \t28.74021572639983\n",
      "영화-드라마 장르와의 일치율은 : \t40.0%\n",
      "영화-드라마 장르의 단어 길이는 : \t829\n",
      "\n",
      "영화-멜로 장르와의 거리는 : \t19.104041956023245\n",
      "영화-멜로 장르와의 거리(원본)는 : \t20.0\n",
      "영화-멜로 장르와의 일치율은 : \t30.0%\n",
      "영화-멜로 장르의 단어 길이는 : \t402\n",
      "\n",
      "영화-애니메이션 장르와의 거리는 : \t22.884816366812586\n",
      "영화-애니메이션 장르와의 거리(원본)는 : \t17.406895185529212\n",
      "영화-애니메이션 장르와의 일치율은 : \t40.0%\n",
      "영화-애니메이션 장르의 단어 길이는 : \t306\n",
      "\n",
      "영화-액션&어드벤쳐 장르와의 거리는 : \t8.407338355894657\n",
      "영화-액션&어드벤쳐 장르와의 거리(원본)는 : \t37.603191353926334\n",
      "영화-액션&어드벤쳐 장르와의 일치율은 : \t60.0%\n",
      "영화-액션&어드벤쳐 장르의 단어 길이는 : \t1419\n",
      "\n",
      "가장 유사한 장르는 TV 연예&오락-기타\n"
     ]
    }
   ],
   "source": [
    "# 샘플 줄거리 데이터 \n",
    "new_content = ' 밀실 안의 살인자, 정유정은 누구인가? 20대 또래 여성을 살해한 정유정의 정체와 범행 동기가 무엇인지에 대해 추적해 본다.'\n",
    "\n",
    "# 샘플 문장 토큰화\n",
    "spliter = Twitter()\n",
    "sample_words = spliter.nouns(new_content)\n",
    "del_sample_words = ['정유', '정은', '누구', '정의', '무엇', '인지', '대해']\n",
    "sample_words = [each_word for each_word in sample_words if each_word not in del_sample_words]\n",
    "\n",
    "# 가장 거리가 짧은 세부 장르 계산용\n",
    "min_distance = 65536\n",
    "min_detail_genre = 'None'\n",
    "\n",
    "# 각 세부 장르별 줄거리를 가지고 단어 사전을 생성하고 샘플 줄거리와\n",
    "# 거리를 비교\n",
    "for detail_genre in data_list:\n",
    "    vectorizer = CountVectorizer(min_df = 1) # 1번만 등장해도 단어 사전에 포함시키도록\n",
    "    \n",
    "    # 장르 별로 줄거리 불러오기 - dict 의 value\n",
    "    contents_tokens = word_vector_dict[detail_genre]\n",
    "    \n",
    "    # 문장 생성\n",
    "    sample_sentence = ''\n",
    "    for sample_word in sample_words:\n",
    "        sample_sentence += (sample_word + ' ')\n",
    "        \n",
    "    sentence = contents_tokens[0] #+ sample_sentence\n",
    "    #print(sentence + '\\n')\n",
    "    \n",
    "    # 생성한 문장을 리스트에 추가\n",
    "    contents_for_vect = []\n",
    "    contents_for_vect.append(sentence)\n",
    "    \n",
    "    # 피처 벡터화 - 띄어쓰기를 기준으로 벡터화\n",
    "    X = vectorizer.fit_transform(contents_for_vect)\n",
    "    # 피처 확인\n",
    "    #print(vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # 샘플 줄거리 문장을 피처 벡터화\n",
    "    new_content_vect = vectorizer.transform([sample_sentence])\n",
    "    #print(new_content_vect)\n",
    "    \n",
    "    # 거리 계산\n",
    "    post_vec = X.getrow(0) # 문장이 1개이므로 첫번째인 0번 인덱스\n",
    "    #print(post_vec)\n",
    "    #print(post_vec.shape[1])\n",
    "    #print(new_content_vect.shape[1])\n",
    "    distance = dist_raw(new_content_vect, post_vec)\n",
    "    \n",
    "    # 세부 장르별 단어의 갯수를 세고 일정 갯수 이하이면 제외\n",
    "    length = post_vec.shape[1]\n",
    "    limit_length = 100\n",
    "    limit_cor = 0.3\n",
    "    if length < limit_length:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        # 일치율 계산하기\n",
    "        count = 0\n",
    "        for item in sample_words:\n",
    "            if item in contents_tokens[0]:\n",
    "                count += 1\n",
    "\n",
    "        cor = count / len(sample_words)\n",
    "        \n",
    "        # 일치율이 기준을 넘는 경우에만 거리를 계산\n",
    "        if cor < limit_cor:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            # 결과 확인 - 장르와의 거리는 줄거리 단어의 길이를 가중치로 반영하여 계산\n",
    "            weighted_distance = distance / (math.log10(length)) / length * 1000\n",
    "            print(detail_genre, ' 장르와의 거리는 : \\t', weighted_distance, sep='') \n",
    "            # 1000을 곱한 이유는 쉽게 보기 위함\n",
    "            print(detail_genre, ' 장르와의 거리(원본)는 : \\t', distance, sep='')\n",
    "            print(detail_genre, ' 장르와의 일치율은 : \\t', cor * 100 , '%', sep='')\n",
    "            print(detail_genre, ' 장르의 단어 길이는 : \\t', length, '\\n',sep='')\n",
    "            \n",
    "            if weighted_distance < min_distance:\n",
    "                min_distance = weighted_distance\n",
    "                min_detail_genre = detail_genre\n",
    "\n",
    "# 최종 결과         \n",
    "print('가장 유사한 장르는 ', min_detail_genre, sep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a9f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0849243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
